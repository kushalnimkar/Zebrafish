{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trajectory Inference (multiple-overlay).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX98W2MQL8Fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# uses modified version of scanpy\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install leidenalg\n",
        "\n",
        "import os, sys\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks/scanpy\"\n",
        "sys.path.append(os.getcwd())\n",
        "import os\n",
        "import time\n",
        "SCRIPT_DIR = os.path.abspath('/content/drive/MyDrive/Colab Notebooks/')\n",
        "!pip install -e \"/content/drive/MyDrive/Colab Notebooks/scanpy\"\n",
        "import scanpy as sc\n",
        "import anndata as ann\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "from matplotlib import figure\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# INPUT_DATA = os.path.join(SCRIPT_DIR, \"DATA\",\"sc2\")\n",
        "DF_PROCESSEDv4_DATAPATH = os.path.join(SCRIPT_DIR, \"DATA\",\"DF\",\"df_processedv4.h5ad\")\n",
        "FIGURE_DIR = os.path.join(SCRIPT_DIR, \"Plots\", \"Initial_Clustering\")\n",
        "!pip freeze \"/content/drive/MyDrive/Colab Notebooks/DATA/requirements.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OEDdyQoCw_a"
      },
      "source": [
        "# Trains binary classifier on provided cluster\n",
        "def train_classifier(t2, scm, clust_idx, use_xgboost=True, method='exact', n_estimators=1300, max_depth=7):\n",
        "  f2 = scm.obs['Timepoint'] == t2\n",
        "  X2 = scm[f2].X\n",
        "  y2 = (scm[f2]).obs[clust_idx]\n",
        "  if use_xgboost:\n",
        "    param_dist = {'method':'exact', 'n_estimators':n_estimators, \n",
        "                  'max_depth': max_depth, 'binary':'logistic'}\n",
        "  else: #TODO: random forest classifier\n",
        "    print(\"Random forest not implemented yet\")\n",
        "    return\n",
        "  clf = XGBClassifier(**param_dist)\n",
        "  start = time.time()\n",
        "  X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.9, test_size=0.1, random_state=2)\n",
        "  # if len(y2_train.unique()) != len(y2_test.unique()):\n",
        "    # raise ValueError(\"Train and test labels do not overlap\")\n",
        "  clf.fit(X2_train, y2_train)\n",
        "  plot_confusion_matrix(clf,X2_test,y2_test)\n",
        "  end = time.time()\n",
        "  print(\"Model split and trained using {} in {} seconds\".format(method, end-start))\n",
        "  return X2_train, X2_test, y2_train, y2_test, clf\n",
        "\n",
        "def timepoint_probabilities(scm, tp, clust, plots, n_neighbors,min_dist, resolution):\n",
        "  scm_n = scm[scm.obs['Timepoint'] == tp]\n",
        "  start = time.time()\n",
        "  sc.pp.neighbors(scm_n, n_neighbors,random_state=1)\n",
        "  sc.tl.umap(scm_n, min_dist, n_components=2, random_state=1, alpha=1)\n",
        "  plots.append(scm_n)\n",
        "  stage = scm_n.obs['Stage'][0]\n",
        "  sc.pl.scatter(scm_n, \n",
        "                title='Timepoint: {} ({}), cells: {}, NN= {}'.format(tp, stage ,scm_n.n_obs, n_neighbors),\n",
        "                basis='umap', color=clust, \n",
        "                save='_XGBOOST_CLUSTPROB_{}_TIMEPOINT_{}.png'.format(clust,tp))\n",
        "  sc.pl.scatter(scm_n, \n",
        "                title='Timepoint: {} ({}), cells: {}, NN= {}'.format(tp, stage ,scm_n.n_obs, n_neighbors),\n",
        "                basis='umap', color='leiden', save='_clust_OUTPUTS_Timepoint_{}.png'.format(tp))\n",
        "  end = time.time()\n",
        "  print(\"Time to visualize: \"+ str(end-start) + \" seconds\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4NjJM8xjzYU"
      },
      "source": [
        "# Graph Boost method\n",
        "def nn_cluster_assignment(scm, tp, clust_idx, max_iter = 2, n_neighbors=15, neighbors_cutoff = 0.3, iteration_cutoff=0.005):\n",
        "  scm_t = scm[scm.obs['Timepoint'] == tp]\n",
        "  sc.pp.neighbors(scm_t, n_neighbors=n_neighbors+1)\n",
        "  srm = scm_t.obsp['distances']\n",
        "  print(\"Number of edges connected to cell 0: {}\", len(np.argwhere(srm[0,:])))\n",
        "  continue_assigning = True\n",
        "  start = time.time()\n",
        "  iter = 0\n",
        "  while continue_assigning and iter <max_iter:\n",
        "    n_unassigned_1 = scm_t[scm_t.obs[clust_idx] == 0].n_obs\n",
        "    print(\"Number of cells not assigned to cluster {}: {}\".format(clust_idx, n_unassigned_1))\n",
        "    for cell_idx in range(srm.shape[0]):\n",
        "      # skip checking on a cell_idx's neighbors if it is already assigned a cluster\n",
        "      if scm_t.obs.at[scm_t.obs.index[cell_idx], clust_idx] == 1:\n",
        "        continue\n",
        "      nearest_obs = np.argwhere(srm[cell_idx,:])[:,1]\n",
        "      vfunc = np.vectorize(lambda x: 1 if scm_t.obs.at[scm_t.obs.index[x], clust_idx] == 1 else 0)\n",
        "      count_neighbors = np.sum(vfunc(nearest_obs))\n",
        "      if count_neighbors/n_neighbors >= neighbors_cutoff:\n",
        "        scm_t.obs.loc[scm_t.obs.index[cell_idx], clust_idx] = 1\n",
        "    n_unassigned_2 = scm_t[scm_t.obs[clust_idx] == 0].n_obs\n",
        "    # stop when new cells are being assigned to clusters at a very small proportion\n",
        "    if n_unassigned_2 > (1-iteration_cutoff)*n_unassigned_1:\n",
        "      continue_assigning = False\n",
        "    iter += 1\n",
        "  print(\"Number of cells not assigned to cluster {}: {}\".format(clust_idx, n_unassigned_2))\n",
        "  end = time.time()\n",
        "  print(\"Time elapsed to conduct graph boost on {} at timepoint: {}: {}\".format(clust_idx, tp, end-start))\n",
        "  return scm_t"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXodALUUCx6v"
      },
      "source": [
        "scm_ml = ann.read(DF_PROCESSEDv4_DATAPATH)\n",
        "scm_ml.obs['leiden'] = scm_ml.obs['leiden'].astype(int)\n",
        "\n",
        "#  add columns for probability and cluster assignments (all zeroes for now)\n",
        "t_final = scm_ml.obs['Timepoint'].max()\n",
        "num_classes = len(scm_ml[scm_ml.obs['Timepoint'] == t_final].obs['leiden'].unique())\n",
        "# Column 'p(ci)' represents probability that an observation belongs to cluster i at t_final\n",
        "prob_df = pd.DataFrame(data=np.zeros((scm_ml.n_obs, num_classes)),\n",
        "                       index=scm_ml.obs.index, \n",
        "                       columns=['p(c'+str(i)+')' for i in range(num_classes)])\n",
        "# Column ci represents formal cell assignment, based off a later-specified p threshold of p(ci)\n",
        "clust_df = pd.DataFrame(data=np.zeros((scm_ml.n_obs, num_classes)),\n",
        "                                    index=scm_ml.obs.index, \n",
        "                                    columns=['c' + str(i) for i in range(num_classes)])\n",
        "scm_ml.obs = pd.concat([scm_ml.obs,prob_df,clust_df],axis=1)\n",
        "\n",
        "# Assign initial ci with 1's to signify a cell belongs to the last timepoint leiden clusters; rest will remain zero \n",
        "for clust_idx in clust_df:\n",
        "  clust_num = int(clust_idx[1])\n",
        "  f = (scm_ml.obs['leiden'] == clust_num) & (scm_ml.obs['Timepoint'] == t_final)\n",
        "  scm_ml.obs.loc[f, clust_idx] = 1\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SiikaatKG4Q"
      },
      "source": [
        "def determine_trajectories(scm_ml, timepoints, clust_ids, p=0.5, max_iter=2, n_neighbors=15, neighbors_cutoff = 0.3, iteration_cutoff=0.005):\n",
        "  n_timepoints = len(timepoints)\n",
        "  for clust_id in clust_ids:\n",
        "    for i in range(n_timepoints-1):      \n",
        "      t2 = timepoints[-1*(i+1)]\n",
        "      t1 = timepoints[-1*(i+2)]\n",
        "      clust_idx = 'c' + str(clust_id)\n",
        "      prob_idx = 'p(' + clust_idx + ')'\n",
        "      X2_train, X2_test, y2_train, y2_test, clf = train_classifier(t2=t2, scm=scm_ml, clust_idx=clust_idx)\n",
        "      labels = y2_test.unique()\n",
        "      labels.sort()\n",
        "      if t2 == t_final:\n",
        "        # Just for completion, assign probabilities for initial timepoint as well\n",
        "        X_t2= scm_ml[scm_ml.obs['Timepoint'] == t2].X\n",
        "        y_t2 = clf.predict_proba(X_t2)\n",
        "        scm_ml.obs.loc[scm_ml.obs['Timepoint'] == t2,prob_idx] = y_t2[:,1]\n",
        "        # plot\n",
        "        # timepoint_probabilities(scm_ml, t2, clust_idx, plots, n_neighbors=15, min_dist=0.3, resolution=1)\n",
        "        # don't need to change cluster assignments since we already did that for t_final\n",
        "      X_t1= scm_ml[scm_ml.obs['Timepoint'] == t1].X\n",
        "      y_t1 = clf.predict_proba(X_t1)\n",
        "      # update new probabilities at t1\n",
        "      scm_ml.obs.loc[scm_ml.obs['Timepoint'] == t1,prob_idx] = y_t1[:,1]\n",
        "      # update specified cluster's assignments for t1\n",
        "      scm_ml.obs.loc[(scm_ml.obs['Timepoint'] == t1) & (scm_ml.obs[prob_idx] > p), clust_idx] = 1\n",
        "      # conduct graph boosting for this specific cluster at t1\n",
        "      scm_t = nn_cluster_assignment(scm_ml, t1, clust_idx, max_iter = max_iter, n_neighbors=n_neighbors, neighbors_cutoff = neighbors_cutoff, iteration_cutoff=iteration_cutoff)\n",
        "      scm_ml.obs.loc[scm_ml.obs['Timepoint'] == t1, clust_idx] = scm_t.obs[clust_idx]\n",
        "      # timepoint_probabilities(scm_ml, t1, clust_idx, plots, n_neighbors=15, min_dist=0.3, resolution=1)\n",
        "  return scm_ml"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzgaepzt-qgR"
      },
      "source": [
        "plots = []\n",
        "clust_ids = [6]\n",
        "neighbors_cutoff = 0.4\n",
        "iteration_cutoff = 0.005\n",
        "max_iter=2\n",
        "n_neighbors = 15\n",
        "p=0.6"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCXJOmK6WtS2",
        "outputId": "b7a77935-1098-4fc9-e6ba-442ba995e521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "scm_ml = determine_trajectories(scm_ml, timepoints, clust_ids, p=p, max_iter=max_iter, n_neighbors=n_neighbors, neighbors_cutoff = neighbors_cutoff, iteration_cutoff=iteration_cutoff)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model split and trained using exact in 154.71463918685913 seconds\n",
            "WARNING: Root cell index 13435 does not exist for 1589 samples. It’s ignored.\n",
            "Number of edges connected to cell 0: {} 15\n",
            "Number of cells not assigned to cluster c6: 1459\n",
            "Number of cells not assigned to cluster c6: 1456\n",
            "Time elapsed to conduct graph boost on c6 at timepoint: 11.0: 0.745445966720581\n",
            "Model split and trained using exact in 49.17544341087341 seconds\n",
            "WARNING: Root cell index 13435 does not exist for 7094 samples. It’s ignored.\n",
            "Number of edges connected to cell 0: {} 15\n",
            "Number of cells not assigned to cluster c6: 6510\n",
            "Number of cells not assigned to cluster c6: 6483\n",
            "Time elapsed to conduct graph boost on c6 at timepoint: 10.0: 3.101881504058838\n",
            "Model split and trained using exact in 282.9654905796051 seconds\n",
            "WARNING: Root cell index 13435 does not exist for 5622 samples. It’s ignored.\n",
            "Number of edges connected to cell 0: {} 15\n",
            "Number of cells not assigned to cluster c6: 5135\n",
            "Number of cells not assigned to cluster c6: 5109\n",
            "Number of cells not assigned to cluster c6: 5065\n",
            "Time elapsed to conduct graph boost on c6 at timepoint: 9.0: 4.99944281578064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvmnCrkBTKWJ"
      },
      "source": [
        "def compare_clustering(scm_ml, timepoints, clust_idx, prob=None, n_rows=8, n_cols=3):\n",
        "  print(clust_idx)\n",
        "  n_timepoints = len(timepoints)\n",
        "  if n_rows * n_cols != 2*n_timepoints:\n",
        "    raise ValueError(\"Number of rows and number of columns must multiply to total number of plots\")\n",
        "  # Don't want the scanpy plot to interpret the values as continuous variables\n",
        "  scm_ml.obs['leiden'] = scm_ml.obs['leiden'].astype(str)\n",
        "  if prob is None:\n",
        "    scm_ml.obs[clust_idx] = scm_ml.obs[clust_idx].astype(str)\n",
        "  fig, ax_arr = plt.subplots(n_rows, n_cols, figsize=(n_cols*10,n_rows*9))\n",
        "  plot_ml_cluster = True\n",
        "  # create tuple array that helps plot the leiden plots and ml clustering results to alternate rows (1st row leiden, second row ml...3rd row leiden, etc.)\n",
        "  new_indices = []\n",
        "  original_indices = list(range(n_timepoints))\n",
        "  slice_width = n_cols\n",
        "  num_repeats = 2 # 1 for ledien cluster plot, 1 for ml plot\n",
        "  for j in range(int(n_rows/2)):\n",
        "    for k in range(num_repeats):\n",
        "      new_indices = new_indices + original_indices[j*slice_width: (j+1)*slice_width]\n",
        "  t_axes_tuple = tuple(zip(new_indices,ax_arr.flatten()))\n",
        "  for i, ax in t_axes_tuple:\n",
        "    if i % n_cols == 0:\n",
        "      plot_ml_cluster = not plot_ml_cluster\n",
        "    t= timepoints[-1 * (i+1)]\n",
        "    scm_t = scm_ml[scm_ml.obs['Timepoint'] == t]\n",
        "    sc.pp.neighbors(scm_t, n_neighbors=15,random_state=1)\n",
        "    sc.tl.umap(scm_t, min_dist=0.3, n_components=2, random_state=1, alpha=1)\n",
        "    if plot_ml_cluster and prob is None:\n",
        "      sc.pl.scatter(scm_t, \n",
        "                  title='iGraphBoost, Timepoint: {}, Cluster: {} n_cells: {}'.format(t, clust_idx, scm_t.n_obs), \n",
        "                  basis='umap', color=clust_idx, ax=ax, show = False)\n",
        "    elif plot_ml_cluster and prob is not None: # scanpy bug with subplots and probability scales\n",
        "      sns.scatterplot(x=scm_t.obsm['X_umap'][:,0], y=scm_t.obsm['X_umap'][:,1], hue=scm_t.obs[clust_idx], ax=ax)\n",
        "    else:\n",
        "      sc.pl.scatter(scm_t, \n",
        "                    title='Leiden clustering, Timepoint: {}, n_cells: {}'.format(t, scm_t.n_obs), \n",
        "                    basis='umap', color='leiden', ax=ax, show = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOhFZhPsx_QJ"
      },
      "source": [
        "for id in clust_ids:\n",
        "  clust_idx = 'c' + str(id)\n",
        "  prob_idx = 'p(c' + str(id) + ')'\n",
        "  compare_clustering(scm_ml, timepoints, clust_idx = prob_idx, prob=True)\n",
        "  plt.tight_layout(pad=3.0)\n",
        "  plt.savefig('{}, num_Neighbors_cutoff = {}, classification_cutoff = {}.png'.format(prob_idx, neighbors_cutoff,p))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7DBnWQkJVC9"
      },
      "source": [
        "sns.heatmap(data=scm_t.obsm['X_pca'], hue=scm_t.obs[clust_idx])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}